<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://yongsik-lee.github.io/marl/feed.xml" rel="self" type="application/atom+xml"/><link href="https://yongsik-lee.github.io/marl/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-04T15:48:56+08:00</updated><id>https://yongsik-lee.github.io/marl/feed.xml</id><title type="html">AI810_Geometric Deep Learning_test</title><subtitle>Home to the 2025 ICLR Blogposts track </subtitle><entry><title type="html">AI810 Blog Post (20205266)</title><link href="https://yongsik-lee.github.io/marl/blog/20205266/" rel="alternate" type="text/html" title="AI810 Blog Post (20205266)"/><published>2025-04-28T00:00:00+08:00</published><updated>2025-04-28T00:00:00+08:00</updated><id>https://yongsik-lee.github.io/marl/blog/20205266</id><content type="html" xml:base="https://yongsik-lee.github.io/marl/blog/20205266/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>This review pairs two thematically distinct yet intellectually adjacent papers: ‚ÄúRegulatory DNA Sequence Design with Reinforcement Learning‚Äù and ‚ÄúGenerator Matching: Generative Modeling with Arbitrary Markov Processes.‚Äù While one operates in the domain of biological sequence design and the other in foundational generative modeling, both tackle a common question at the heart of intelligent system design: how can we guide generative processes using structured priors and dynamic feedback?</p> <p>The first paper explores how reinforcement learning‚Äîaugmented with biological knowledge‚Äîcan improve the optimization of cis-regulatory DNA sequences, a crucial problem in synthetic biology. The second paper introduces a unifying mathematical framework for generative modeling through the lens of parameterized Markov processes, offering a flexible alternative to existing paradigms like diffusion and flow models.</p> <p>From the vantage point of RL and LLM-based agents, both works offer rich insights. TACO (Paper 1) exemplifies reward shaping and policy optimization in a constrained generative environment, while Generator Matching (Paper 2) provides a theoretical scaffold for modeling and composing stochastic transitions‚Äîakin to environment dynamics in model-based RL or planning behaviors in complex multi-agent systems. Despite addressing different domains, both papers converge on a shared ambition: to systematically construct or adapt generative mechanisms toward target outcomes using theoretically grounded tools.</p> <h2 id="regulatory-dna-sequence-design-with-reinforcement-learning-">Regulatory DNA Sequence Design with Reinforcement Learning <d-cite key="yang2025regulatory"></d-cite></h2> <h3 id="-biological-background">üìå Biological Background</h3> <p>As we come from an AI background, I first provide a brief summary of relevant biological concepts appearing in this paper, based on my own understanding with external sources.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-biology-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-biology-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-biology-1400.webp"/> <img src="/marl/assets/img/2025-04-28-20205266/TACO-biology.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Conceptual flow of gene expression control. </div> <ul> <li><strong>DNA</strong>: a sequence of nucleotides (A, T, C, and G) that encodes genetic information. <ul> <li><strong>Gene</strong>: a sub-sequence of DNA. Genes are not always active. <strong>Gene expression</strong> is the process that encodes a gene‚Äôs information into proteins.</li> <li><strong>Cis-regulatory elements (CRE)</strong>: a non-coding sub-sequence of DNA that acts as on/off switch to control gene expression. A <strong>promoter</strong> determines when and where a gene is activated, and an <strong>enhancer</strong> boosts the level of gene expression. The ability of a CRE to modulate gene expression is referred to as its <strong>fitness</strong>. <ul> <li><strong>Transcription Factor Binding Sites (TFBS)</strong>: a short sequence motif within a CRE.</li> </ul> </li> </ul> </li> <li><strong>Transcription Factor (TF)</strong>: a protein that recognizes and binds to a specific TFBS. This binding influences a CRE‚Äôs regulation of gene expression. An <strong>activator</strong> TF promotes gene transcription and expression, while a <strong>repressor</strong> TF hinders them.</li> </ul> <p>In summary, a TF binding to a CRE via its TFBS modulates gene expression and each gene is regulated by distinct TFs and CREs.</p> <h3 id="-overview">üìå Overview</h3> <h4 id="motivation">Motivation</h4> <p>CREs play an essential role in regulating gene expression in a cell-type-specific manner. While millions of putative CREs have been identified over the past decade, most are naturally evolved and cover only a small region of the possible sequence space. Therefore, the design of synthetic CREs with <em>desired fitness</em> is a promising direction, with broad applications across diverse domains.</p> <p>The design of high-fitness CREs has primarily relied on <em>directed evolution</em>, which iteratively mutates and selects sequences in wet-lab settings. More recently, <em>fitness prediction models</em> have been utilized as reward models to guide CRE optimization. However, current methods suffer from two limiations:</p> <ul> <li>Although the sequence space is large, they rely on local modifcation of existing or random sequences with iterative optimization, resulting in <em>local optima</em> and <em>low diversity</em>.</li> <li>They generally do not utilize <em>biological prior knowledge</em>.</li> </ul> <h4 id="key-contributions">Key Contributions</h4> <p>This paper proposes <strong>TACO</strong> (<strong>T</strong>FBS-<strong>A</strong>ware <strong>C</strong>is-regulatory element <strong>O</strong>ptimization), a RL fine-tuning method for a pre-trained autoregressive (AR) DNA model incorporating biological priors of TFBS information to improve CRE optimization. The key contributions are:</p> <ul> <li><strong>RL Fine-tuning for Pre-trained AR DNA Generative Models</strong>: The suggested paradigm enables the generation of sequences with significantly higher diversity while also exploring those with superior functional performance.</li> <li><strong>Biologically-informed Prior Guided TFBS Reward</strong>: The authors discover that using only TFBS frequency features of a CRE sequence can achieve high performance on CRE fitness prediction tasks. Moreover, the potential contribution of each TFBS is inferred via SHAP value and implemented as additional rewards.</li> <li><strong>Generation of high fitness and diversity Cell-type specific CREs</strong>: TACO is evaluated under different optimization settings (active learning and offline model-based optimization) on real-world datasets and demostrated its effectiveness.</li> </ul> <h3 id="-method">üìå Method</h3> <h4 id="problem-formulation">Problem Formulation</h4> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-method-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-method-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-method-1400.webp"/> <img src="/marl/assets/img/2025-04-28-20205266/TACO-method.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Overview of TACO, illustrating AR generation of a DNA sequence (BOS represents the beginning of the sequence). </div> <p>A DNA sequence \(X = ( x_1, \cdots, x_L )\) is defined as a sequence of necleotides, where \(x_i \in \{A, C, G, T \}\) represents the nucleotide at the \(i\)-th position. The sequence has length \(L\). A large-scale dataset of CRE sequences with fitness measurements, \(D = \{ (X_1, f (X_1)), \cdots, (X_N, f (X_N)) \}\), is available. \(D_\text{low}\) is a subset of low-fitness sequences. In RL framework, the sequence generation is formulated as a <em>Markov Decision Process (MDP)</em>:</p> <ul> <li><strong>State</strong>: \(s_i\), a partially generated DNA sequences up to time step \(i\)</li> <li><strong>Action</strong>: \(a_i \in \{A, C, G, T \}\), the next nucleotide at position \(i\)</li> <li><strong>Policy</strong>: \(\pi_\theta\), the AR generative model</li> <li><strong>Reward</strong>: \(r(s_{i-1}, a_i) = \begin{cases} r_{\text{fitness}}, &amp; \text{if } i = L \\ r_{\text{TFBS}}(t), &amp; \text{if } a_i \text{ results in a TFBS } t \in T \\ 0, &amp; \text{otherwise} \end{cases}\)</li> </ul> <p>The generation process is illustrated in the above figure. The process terminates when the sequence length reaches $L$ and \(r_{\text{fitness}}\) is given by the reward model. Whenever a TFBS \(T = \{t_1, t_2, \cdots, t_n\}\) is identified, a positive (or negative) reward \(r_{\text{TFBS}}(t)\) is given for generating activating (or repressive) TFBS.</p> <h4 id="step-1-pre-training-cre-specific-ar-model">Step 1: Pre-training CRE-specific AR Model</h4> <p>In the pre-training stage, HyenaDNA <d-cite key="nguyen2023hyenadna"></d-cite> is adapted for the AR model by continual training on \(D_{\text{low}}\). As HyenaDNA is trained on the entire human genome, continual pre-training is performed for CRE-specific regulatory patterns. Furthermore, pre-training on \(D_{\text{low}}\) helps the policy generate sequences that resemble the true CRE distribution <d-cite key="jin2020multi"></d-cite><d-cite key="chen2021molecule"></d-cite>, offering a good starting point for RL fine-tuning. The objective is to minimize:</p> \[\min_{\theta} \mathbb{E}_{x \sim D_{\text{low}}} \left[ \sum_{i=1}^{L} -\log \pi_{\theta}(a_i \mid a_1, \cdots, a_{i-1}) \right]\] <h4 id="step-2-rl-fine-tuning-for-ar-dna-models">Step 2: RL Fine-tuning for AR DNA Models</h4> <p>With the aforementioned MDP formulation, the objective in RL fine-tuning stage is to maximize the expected cumulative rewards:</p> \[\max_{\theta} J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \sum_{i=1}^{L} r(s_{i-1}, a_i) \right]\] <p>REINFORCE <d-cite key="williams1992simple"></d-cite> is used to train the policy, and a hill climbing replay buffer and entropy regularization are utilized as auxiliary techniques following prior works <d-cite key="blaschke2020reinvent"></d-cite><d-cite key="ghugaresearching"></d-cite> to balance exploration and exploitation, thus improving performance.</p> <h4 id="inference-of-tfbs-regulatory-roles-integrating-biological-prior">Inference of TFBS Regulatory Roles (Integrating Biological Prior)</h4> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-method2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-method2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-20205266/TACO-method2-1400.webp"/> <img src="/marl/assets/img/2025-04-28-20205266/TACO-method2.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Inference of TFBS Reward $r_{\text{TFBS}}(t)$ </div> <p>Firstly, construct the feature vector \(h(X) = [h_1(X), h_2(X), \cdots, h_n(X)]\) where \(h_j(X)\) denotes the frequency of the TFBS \(t_j\) in sequence \(X\). LightGBM <d-cite key="ke2017lightgbm"></d-cite>, a decision-tree model, is trained to predict CRE fitness with this feature.</p> <p>Then the contribution of each TFBS frequency feature \(h_j(X)\) to the fitness prediction of the LightGBM model is inferred using SHAP values <d-cite key="lundberg2017unified"></d-cite> <d-footnote>SHAP values are a theoretically grounded method to estimate the contribution of each feature to the prediction of a model.</d-footnote>. The SHAP value \(\phi_j(X)\) for \(j\)-th TFBS \(t_j\) in sequence \(X\) is:</p> \[\phi_j(X) = \sum_{S \subseteq \{1, \dots, n\} \setminus \{j\}} \frac{|S|!(n - |S| - 1)!}{n!} \left( \hat{f}(S \cup \{j\}) - \hat{f}(S) \right)\] <p>where \(S\) is a subset of features not containing \(j\) and \(\hat{f}\) is the model prediction. Then the TFBS reward \(r_{\text{TFBS}}(t)\) is computed as:</p> \[r_{\text{TFBS}}(t) = \begin{cases} \alpha \cdot \mu_\phi(t), &amp; \text{if } p\text{-value} &lt; 0.05 \\ 0, &amp; \text{otherwise} \end{cases}\] <p>where \(\alpha\) is a hyperparameter and \(\mu_\phi(t)\) is the mean SHAP value of TFBS \(t\) across the dataset. <d-footnote> By assigning rewards only when p-value is less than 0.05, only statistically significant TFBSs contribute to the reawrds. </d-footnote> These rewards are incorporated into the RL fine-tuning to encourage activator TFBSs and discourage repressive TFBSs.</p> <h3 id="-results--analysis">üìå Results &amp; Analysis</h3> <p>The experiments are conducted on two datasets: <strong>yeast promoter</strong>, which includes two types of growth media (<em>complex</em> and <em>defined</em>) with DNA sequence length 80, and <strong>human enhancer</strong>, which consists of three cell lines (<em>HepG2</em>, <em>K562</em>, and <em>SK-N-SH</em>) with sequence length 200. MPRAs were employed to obtain all paired CRE sequences and their corresponding fitness measurements.</p> <p>There evaluation metrics are used. <em>Top</em> is the mean fitness of highest-performaing 16 sequences from the optimized set \(\Chi^* = \{X_1, \ldots, X_K\}\) of 256 sequences. <d-footnote> In each optimization round, $K=256$ sequences are generated. </d-footnote> Both <em>Medium</em> and <em>Diversity</em> are computed using the highest-performing 128 sequences from the set of 256 sequences. <em>Medium</em> is the median fitness among 128 sequences, and <em>Diversity</em> is the median pairwise distance between all paris within 128 sequences.</p> <h4 id="experimental-summary">Experimental Summary</h4> <p>The evaluation covers two domains:</p> <ul> <li><strong>Yeast promoters</strong> (short sequences, simpler regulatory grammar).</li> <li><strong>Human enhancers</strong> (longer, cell-type-specific complexity).</li> </ul> <p>Settings:</p> <ul> <li><strong>Active Learning</strong>: The oracle is visible during training.</li> <li><strong>Offline Model-Based Optimization (MBO)</strong>: The oracle is hidden; optimization relies on a surrogate.</li> </ul> <p>Baselines include BO, CMAES, AdaLead, PEX, and DNARL.</p> <h4 id="empirical-analysis">Empirical Analysis</h4> <ul> <li><strong>Yeast Results</strong>: All models achieved max fitness, but <strong>TACO surpassed all in diversity</strong>, suggesting better exploration.</li> <li><strong>Human Enhancers</strong>: <ul> <li><strong>TACO maintained the highest diversity</strong> while achieving comparable or superior fitness, particularly in the K562 and SK-N-SH cell lines.</li> <li><strong>PEX</strong> had high fitness but low diversity.</li> <li><strong>AdaLead</strong> was fast but prone to premature convergence.</li> </ul> </li> <li><strong>Offline MBO</strong>: TACO preserved its edge in diversity and achieved strong performance without oracle access.</li> </ul> <p>Notably, TACO‚Äôs use of <strong>biologically informed rewards</strong> enabled it to escape local optima and avoid overfitting to surrogate models, a known failure mode in offline optimization.</p> <h4 id="strengths">Strengths</h4> <ul> <li><strong>Innovative use of TFBS-informed rewards</strong></li> <li><strong>High diversity and fitness</strong>‚Äîcritical in real applications</li> <li><strong>Robust performance</strong> across domains and training settings</li> <li><strong>Strong theoretical grounding</strong> in MDP and interpretable feature attribution</li> </ul> <h4 id="limitations">Limitations</h4> <ul> <li><strong>Static TFBS vocabulary</strong>: Based on a fixed database; dynamic motif discovery is unexplored.</li> <li><strong>No modeling of TF interactions or orientation</strong>: Limits biological realism.</li> <li><strong>Fitness oracle is assumed accurate</strong>: Real-world biological validation is absent.</li> <li><strong>Generality across organisms</strong>: Not yet demonstrated outside yeast/human.</li> </ul> <h3 id="personal-take--commentary">Personal Take &amp; Commentary</h3> <h4 id="interpretation-from-my-research-background">Interpretation from My Research Background</h4> <p>As a researcher in <strong>RL and multi-agent systems</strong>, particularly with recent work in <strong>LLM-based agents</strong>, this paper feels like a well-integrated application of RL to structured sequence design. The use of a generative AR model as a policy echoes <strong>autoregressive planning</strong> in agents, and the reward shaping via TFBS knowledge mirrors <strong>value shaping in multi-agent learning</strong> to incorporate domain priors.</p> <p>Moreover, the method‚Äôs ability to balance <strong>exploration (diversity)</strong> and <strong>exploitation (fitness)</strong> under surrogate uncertainty aligns with ideas from <strong>conservative RL</strong> and <strong>offline policy optimization</strong> in LLM agents. The idea of inferring ‚Äúreward models‚Äù from interpretable features also shares philosophical ground with reward learning in autonomous agents.</p> <h4 id="implications-for-future-research">Implications for Future Research</h4> <ul> <li><strong>Cross-domain generalization</strong>: Could TACO-style methods transfer to protein engineering or RNA design with appropriate priors?</li> <li><strong>Multi-objective optimization</strong>: Incorporating trade-offs (e.g., tissue specificity vs. stability) could benefit from <strong>Pareto front-based RL</strong>.</li> <li><strong>Hierarchical action spaces</strong>: DNA motifs are naturally hierarchical. Could <strong>options or temporally extended actions</strong> improve sample efficiency?</li> <li><strong>Language model parallels</strong>: Applying chain-of-thought prompting or instruction tuning to DNA generation is an intriguing idea.</li> </ul> <h4 id="critical-commentary">Critical Commentary</h4> <ul> <li>While TACO clearly advances the state of the art, it remains dependent on oracle quality. Exploring <strong>uncertainty-aware RL</strong> or <strong>model-based planning</strong> using ensembles could mitigate this.</li> <li>The <strong>lack of experimental wet-lab validation</strong> leaves the practical impact of the method speculative, though this is a systemic issue in computational biology.</li> <li>The method could benefit from <strong>probabilistic modeling of biological constraints</strong>, perhaps by fusing the AR model with a <strong>variational framework</strong>.</li> </ul> <h2 id="-tldr">üåü TL;DR</h2> <p><strong>TACO is a biologically-aware RL method for DNA sequence design that integrates generative modeling and interpretable reward shaping.</strong> It sets a new benchmark in CRE optimization by balancing fitness and diversity‚Äîtwo goals often in conflict‚Äîand represents a compelling bridge between computational biology and reinforcement learning. For RL researchers, this is a refreshing demonstration of classic ideas in a novel and high-impact domain.</p> <h2 id="generator-matching-generative-modeling-with-arbitrary-markov-processes-">Generator Matching: Generative Modeling with Arbitrary Markov Processes <d-cite key="holderrieth2025generator"></d-cite></h2> <h3 id="introduction-1">Introduction</h3> <h4 id="motivation-1">Motivation</h4> <p>In recent years, generative modeling has been dominated by paradigms such as <strong>VAEs</strong>, <strong>GANs</strong>, <strong>Diffusion Models</strong>, and <strong>Flow Models</strong>. Despite their differences, these models share a structural similarity: they operate over <strong>Markovian transformations of probability distributions</strong>, incrementally transforming simple priors into complex data distributions.</p> <p>This paper introduces <strong>Generator Matching (GM)</strong>, a framework that unifies these approaches under the abstraction of <strong>parameterized Markov generators</strong>. This unification not only connects flow-based and diffusion models but also reveals previously unexplored classes of generative processes, such as jump processes, and provides a principled method for combining them.</p> <h4 id="problem-statement">Problem Statement</h4> <p>How can we construct a scalable, flexible, and modality-agnostic generative modeling framework grounded in the theory of <strong>Markov processes</strong> that both unifies existing methods and enables the development of new ones?</p> <h4 id="key-contributions-1">Key Contributions</h4> <ul> <li><strong>Unified Framework</strong>: Proposes <strong>Generator Matching</strong>, generalizing flow matching, diffusion models, and discrete diffusion models.</li> <li><strong>Universal Characterization</strong>: Provides a comprehensive characterization of Markov process generators in Euclidean and discrete spaces.</li> <li><strong>New Model Class</strong>: Introduces <strong>jump models</strong> in $\mathbb{R}^d$ as a novel generative modeling approach.</li> <li><strong>Model Combinations</strong>: Introduces <strong>Markov superpositions</strong> and principled multimodal model composition.</li> <li><strong>Empirical Validation</strong>: Demonstrates competitive performance in image and multimodal protein generation.</li> </ul> <h3 id="method">Method</h3> <h3 id="core-model-architecture--theoretical-framework">Core Model Architecture / Theoretical Framework</h3> <p>The GM framework is based on the <strong>infinitesimal generator</strong> $L_t$ of a Markov process $(X_t)_{t \in [0,1]}$, satisfying the <strong>Kolmogorov Forward Equation (KFE)</strong>:</p> \[\partial_t \mathbb{E}_{x \sim p_t}[f(x)] = \mathbb{E}_{x \sim p_t}[L_t f(x)]\] <p>The approach involves:</p> <ul> <li> <table> <tbody> <tr> <td>Selecting a <strong>conditional probability path</strong> $p_t(\cdot</td> <td>z)$ that interpolates between a simple prior $p_0$ and a delta distribution at data point $z$.</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>Deriving a <strong>conditional generator</strong> $L^z_t$ satisfying the KFE for $p_t(\cdot</td> <td>z)$.</td> </tr> </tbody> </table> </li> <li>Aggregating these to obtain the <strong>marginal generator</strong>:</li> </ul> \[L_t f(x) = \mathbb{E}_{z \sim p_{1|t}(\cdot | x)}[L^z_t f(x)]\] <p>Training involves minimizing a <strong>conditional Generator Matching (CGM) loss</strong> using a <strong>Bregman divergence</strong> between the ground truth and parameterized generator outputs.</p> <p>In Euclidean space, the generator can be expressed as:</p> \[L_t f(x) = \nabla f(x)^T u_t(x) + \frac{1}{2} \text{Tr}\left[\nabla^2 f(x) \cdot \sigma_t^2(x)\right] + \int [f(y) - f(x)] Q_t(dy; x)\] <p>This formulation unifies:</p> <ul> <li>Flows: via drift $u_t$</li> <li>Diffusions: via noise $\sigma_t$</li> <li>Jumps: via rate kernel $Q_t$</li> </ul> <h3 id="results">Results</h3> <h4 id="experimental-summary-1">Experimental Summary</h4> <p>Experiments were conducted on:</p> <ul> <li><strong>Image generation</strong> (CIFAR-10, ImageNet32)</li> <li><strong>Multimodal protein design</strong> (combining structure and sequence modalities)</li> </ul> <p>Key findings:</p> <ul> <li><strong>Jump models</strong>, a novel class, exhibit reasonable generative capacity.</li> <li><strong>Markov superpositions</strong> (e.g., combining flow and jump models) enhance FID scores.</li> <li><strong>Multimodal extensions</strong> demonstrate state-of-the-art diversity in protein generation.</li> </ul> <h4 id="empirical-analysis-1">Empirical Analysis</h4> <h5 id="image-generation">Image Generation</h5> <ul> <li><strong>Jump models</strong> perform adequately on CIFAR-10 and ImageNet32 but do not surpass finely tuned flow/diffusion models.</li> <li>Combining <strong>jump + flow</strong> via superpositions yields improved FID scores compared to individual models.</li> <li>Hybrid sampling (Euler for jumps, 2nd order ODE for flows) achieves the best results.</li> </ul> <table> <thead> <tr> <th>Model</th> <th>CIFAR-10 (FID)</th> <th>ImageNet32 (FID)</th> </tr> </thead> <tbody> <tr> <td>Flow (Euler)</td> <td>2.94</td> <td>4.58</td> </tr> <tr> <td>Jump (Euler)</td> <td>4.23</td> <td>7.66</td> </tr> <tr> <td>Jump + Flow (Mixed)</td> <td><strong>2.36</strong></td> <td><strong>3.33</strong></td> </tr> </tbody> </table> <h5 id="protein-generation">Protein Generation</h5> <ul> <li>Integration of SO(3) jump models into MultiFlow improves <strong>diversity</strong> and <strong>novelty</strong>.</li> <li>GM enables seamless <strong>multimodal state space modeling</strong>.</li> </ul> <h4 id="strengths-1">Strengths</h4> <ul> <li><strong>Theoretical Depth</strong>: Grounded in stochastic process theory, offering solid derivations and generality.</li> <li><strong>Modality-Agnostic</strong>: Applicable across $\mathbb{R}^d$, discrete spaces, and manifolds (e.g., SO(3)).</li> <li><strong>Unified Perspective</strong>: Provides a principled framework encompassing various generative paradigms.</li> <li><strong>Innovative Potential</strong>: Introduces new design principles, particularly in combining generative models across modalities and mechanisms (flow, diffusion, jumps).</li> <li><strong>Empirical Validation</strong>: Demonstrates the practical viability of the framework through experiments on image and protein generation tasks.</li> </ul> <h4 id="limitations-1">Limitations</h4> <ul> <li><strong>Sampling Efficiency</strong>: Sampling methods for jump models are less optimized compared to flows; only Euler methods are currently available.</li> <li><strong>Training Stability</strong>: The impact of jump-induced discontinuities on training stability is not thoroughly explored.</li> <li><strong>Computational Overhead</strong>: Learning and simulating general generators, especially those involving integration over jump measures, can be computationally intensive.</li> <li><strong>Comparative Analysis</strong>: Limited comparison to autoregressive models, which are prevalent in many multimodal tasks (e.g., LLMs for text).</li> </ul> <h3 id="personal-take--commentary-1">Personal Take &amp; Commentary</h3> <h4 id="interpretation-from-my-rl--multi-agent--llm-agent-background">Interpretation from My RL / Multi-Agent / LLM Agent Background</h4> <p>From the perspective of <strong>Reinforcement Learning</strong> and <strong>LLM-based agents</strong>, the concept of parameterizing <strong>Markov generators</strong> parallels the modeling of <strong>transition dynamics</strong> in model-based RL. Just as structured priors in environment modeling can enhance planning, Generator Matching offers a structured approach to define transition dynamics of distributions toward a data manifold.</p> <p>In <strong>multi-agent systems</strong>, GM‚Äôs framework for <strong>composing models</strong> (Markov superpositions, multimodal joints) suggests intriguing possibilities: combining agents with different generative priors or handling discrete-continuous hybrid state-action spaces.</p> <p>Furthermore, the <strong>Bregman divergence-based CGM loss</strong> generalizes many losses used in score-based models and could be adaptable to RL-style divergence regularization objectives.</p> <h4 id="implications-for-future-research-1">Implications for Future Research</h4> <ol> <li><strong>RL Applications</strong>: Exploring GM-inspired generators for learning flexible environment models in stochastic settings.</li> <li><strong>LLM Agents</strong>: Investigating the discrete diffusion perspective of language generation as an alternative to autoregressive decoding.</li> <li><strong>Control as Generation</strong>: Viewing control policies as generators transforming initial states to desired outcomes, potentially inspiring new training objectives for hierarchical policies.</li> </ol> <h4 id="critical-commentary-1">Critical Commentary</h4> <ul> <li>The <strong>mathematical rigor</strong> is commendable, but practical challenges, especially in efficient sampling and scalable implementation, need further exploration. Real-world applications require robust inference schemes for jump models.</li> <li>The treatment of <strong>multimodality</strong> is theoretically sound but may oversimplify practical complexities, as real tasks involve intricate conditional dependencies.</li> <li><strong>Ablation studies</strong> on the expressive benefits of modeling diffusion versus jump components separately would provide deeper insights.</li> <li> <table> <tbody> <tr> <td>The assumption of access to the posterior $p_{1</td> <td>t}(z</td> <td>x)$ may pose challenges in complex domains, as approximations could become bottlenecks.</td> </tr> </tbody> </table> </li> </ul> <h2 id="-tldr-1">üìå TL;DR</h2> <p><strong>Generator Matching</strong> presents a mathematically elegant and theoretically rich foundation for generative modeling using arbitrary Markov processes. It unifies existing methods under a cohesive framework and introduces powerful new design principles, particularly in combining and composing generative models across modalities and mechanisms. While practical challenges remain, especially concerning jump-based sampling and training, the framework opens exciting avenues for applications in RL, LLMs, and beyond.</p> <h2 id="conclusion">Conclusion</h2> <p>Both papers, though rooted in different problem domains, demonstrate how structured guidance‚Äîwhether in the form of reward functions or stochastic generators‚Äîcan profoundly influence generative performance. TACO operationalizes reinforcement learning with interpretable, biologically grounded reward shaping, showing how domain priors can lead to both better optimization and greater output diversity. Generator Matching, on the other hand, reimagines generative modeling itself as a problem of parameterizing transitions in a Markovian space, offering a versatile and modular approach to synthesizing data across modalities.</p> <p>For researchers in reinforcement learning and LLM-based agents, these works offer complementary lessons. TACO echoes challenges in offline RL and exploration under uncertainty‚Äîissues also central to agent design in partially observable or data-scarce environments. Generator Matching suggests a formalism for model-based generation and planning, with intriguing implications for LLMs as stochastic transformers of information states, potentially inspiring new agent design strategies based on generator composition.</p> <p>Finally, from a multi-agent systems perspective, both methods hint at future directions: in TACO, one could envision population-based or competitive optimization of DNA sequences; in Generator Matching, the compositionality of generators suggests a modular approach to modeling heterogeneous agent behaviors or hybrid continuous-discrete action spaces.</p> <p>Together, these papers underscore a powerful trend: bridging generative modeling with policy design, whether for biology, vision, or intelligent agents. Their relevance spans from synthetic cells to synthetic cognition‚Äîunited by a shared focus on controlled, high-fidelity generation in structured environments.</p>]]></content><author><name>Yongsik Lee</name></author><summary type="html"><![CDATA[This blogpost reviews two ICLR 2025 papers, one on RL-guided DNA sequence design (TACO), and another on a unified generative modeling framework based on Markov processes (Generator Matching). Though from different domains, both highlight how structured priors and guided dynamics improve generative outcomes. Their pairing reveals shared insights relevant to reinforcement learning and LLM-based agents, especially in offline optimization, reward shaping, and multi-agent compositionality. For researchers in intelligent agent design, these works offer complementary views on controllable generation‚Äîwhether in biology, vision, or language.]]></summary></entry><entry><title type="html">Sample Blog Post</title><link href="https://yongsik-lee.github.io/marl/blog/distill-example/" rel="alternate" type="text/html" title="Sample Blog Post"/><published>2025-04-28T00:00:00+08:00</published><updated>2025-04-28T00:00:00+08:00</updated><id>https://yongsik-lee.github.io/marl/blog/distill-example</id><content type="html" xml:base="https://yongsik-lee.github.io/marl/blog/distill-example/"><![CDATA[<p>Note: please use the table of contents as defined in the front matter rather than the traditional markdown styling.</p> <h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <h2 id="images-and-figures">Images and Figures</h2> <p>Its generally a better idea to avoid linking to images hosted elsewhere - links can break and you might face losing important information in your blog post. To include images in your submission in this way, you must do something like the following:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include figure.html path="assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" %}
</code></pre></div></div> <p>which results in the following image:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/iclr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/iclr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/iclr-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/iclr.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To ensure that there are no namespace conflicts, you must save your asset to your unique directory <code class="language-plaintext highlighter-rouge">/assets/img/2025-04-28-[SUBMISSION NAME]</code> within your submission.</p> <p>Please avoid using the direct markdown method of embedding images; they may not be properly resized. Some more complex ways to load images (note the different styles of the shapes/shadows):</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/9-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/8-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/8.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/10-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/10.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/11-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/11.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/12-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/12.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/marl/assets/img/2025-04-28-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/marl/assets/img/2025-04-28-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/marl/assets/img/2025-04-28-distill-example/7-1400.webp"/> <img src="/marl/assets/img/2025-04-28-distill-example/7.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="interactive-figures">Interactive Figures</h3> <p>Here‚Äôs how you could embed interactive figures that have been exported as HTML files. Note that we will be using plotly for this demo, but anything built off of HTML should work (<strong>no extra javascript is allowed!</strong>). All that‚Äôs required is for you to export your figure into HTML format, and make sure that the file exists in the <code class="language-plaintext highlighter-rouge">assets/html/[SUBMISSION NAME]/</code> directory in this repository‚Äôs root directory. To embed it into any page, simply insert the following code anywhere into your page.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include [FIGURE_NAME].html %} 
</code></pre></div></div> <p>For example, the following code can be used to generate the figure underneath it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">density_mapbox</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span> <span class="n">lat</span><span class="o">=</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="sh">'</span><span class="s">Magnitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">center</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mapbox_style</span><span class="o">=</span><span class="sh">"</span><span class="s">stamen-terrain</span><span class="sh">"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="sh">'</span><span class="s">./assets/html/2025-04-28-distill-example/plotly_demo_1.html</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>And then include it with the following:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"l-page"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;iframe</span> <span class="na">src=</span><span class="s">"{{ 'assets/html/2025-04-28-distill-example/plotly_demo_1.html' | relative_url }}"</span> <span class="na">frameborder=</span><span class="s">'0'</span> <span class="na">scrolling=</span><span class="s">'no'</span> <span class="na">height=</span><span class="s">"600px"</span> <span class="na">width=</span><span class="s">"100%"</span><span class="nt">&gt;&lt;/iframe&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> <p>Voila!</p> <div class="l-page"> <iframe src="/marl/assets/html/2025-04-28-distill-example/plotly_demo_1.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well‚Äâ‚Äî‚Äâthe authors are human and it‚Äôs nice for them to have the community associate them with their work.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr/> <h2 id="code-blocks">Code Blocks</h2> <p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. You can try toggling it on or off yourself below:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr/> <h2 id="diagrams">Diagrams</h2> <p>This theme supports generating various diagrams from a text description using <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> plugin. Below, we generate a few examples of such diagrams using languages such as <a href="https://mermaid-js.github.io/mermaid/" target="\_blank">mermaid</a>, <a href="https://plantuml.com/" target="\_blank">plantuml</a>, <a href="https://vega.github.io/vega-lite/" target="\_blank">vega-lite</a>, etc.</p> <p><strong>Note:</strong> different diagram-generation packages require external dependencies to be installed on your machine. Also, be mindful of that because of diagram generation the first time you build your Jekyll website after adding new diagrams will be SLOW. For any other details, please refer to <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> README.</p> <p><strong>Note:</strong> This is not supported for local rendering!</p> <p>The diagram below was generated by the following code:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% mermaid %}
sequenceDiagram
    participant John
    participant Alice
    Alice-&gt;&gt;John: Hello John, how are you?
    John--&gt;&gt;Alice: Great!
{% endmermaid %}
</code></pre></div></div> <div class="jekyll-diagrams diagrams mermaid"> <svg id="mermaid-1749023341419" width="100%" xmlns="http://www.w3.org/2000/svg" height="100%" style="max-width:450px;" viewBox="-50 -10 450 231"><style>#mermaid-1749023341419 .label{font-family:trebuchet ms,verdana,arial;color:#333}#mermaid-1749023341419 .node circle,#mermaid-1749023341419 .node ellipse,#mermaid-1749023341419 .node polygon,#mermaid-1749023341419 .node rect{fill:#ececff;stroke:#9370db;stroke-width:1px}#mermaid-1749023341419 .node.clickable{cursor:pointer}#mermaid-1749023341419 .arrowheadPath{fill:#333}#mermaid-1749023341419 .edgePath .path{stroke:#333;stroke-width:1.5px}#mermaid-1749023341419 .edgeLabel{background-color:#e8e8e8}#mermaid-1749023341419 .cluster rect{fill:#ffffde!important;stroke:#aa3!important;stroke-width:1px!important}#mermaid-1749023341419 .cluster text{fill:#333}#mermaid-1749023341419 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:trebuchet ms,verdana,arial;font-size:12px;background:#ffffde;border:1px solid #aa3;border-radius:2px;pointer-events:none;z-index:100}#mermaid-1749023341419 .actor{stroke:#ccf;fill:#ececff}#mermaid-1749023341419 text.actor{fill:#000;stroke:none}#mermaid-1749023341419 .actor-line{stroke:grey}#mermaid-1749023341419 .messageLine0{marker-end:"url(#arrowhead)"}#mermaid-1749023341419 .messageLine0,#mermaid-1749023341419 .messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#mermaid-1749023341419 #arrowhead{fill:#333}#mermaid-1749023341419 #crosshead path{fill:#333!important;stroke:#333!important}#mermaid-1749023341419 .messageText{fill:#333;stroke:none}#mermaid-1749023341419 .labelBox{stroke:#ccf;fill:#ececff}#mermaid-1749023341419 .labelText,#mermaid-1749023341419 .loopText{fill:#000;stroke:none}#mermaid-1749023341419 .loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#ccf}#mermaid-1749023341419 .note{stroke:#aa3;fill:#fff5ad}#mermaid-1749023341419 .noteText{fill:#000;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:14px}#mermaid-1749023341419 .section{stroke:none;opacity:.2}#mermaid-1749023341419 .section0{fill:rgba(102,102,255,.49)}#mermaid-1749023341419 .section2{fill:#fff400}#mermaid-1749023341419 .section1,#mermaid-1749023341419 .section3{fill:#fff;opacity:.2}#mermaid-1749023341419 .sectionTitle0,#mermaid-1749023341419 .sectionTitle1,#mermaid-1749023341419 .sectionTitle2,#mermaid-1749023341419 .sectionTitle3{fill:#333}#mermaid-1749023341419 .sectionTitle{text-anchor:start;font-size:11px;text-height:14px}#mermaid-1749023341419 .grid .tick{stroke:#d3d3d3;opacity:.3;shape-rendering:crispEdges}#mermaid-1749023341419 .grid path{stroke-width:0}#mermaid-1749023341419 .today{fill:none;stroke:red;stroke-width:2px}#mermaid-1749023341419 .task{stroke-width:2}#mermaid-1749023341419 .taskText{text-anchor:middle;font-size:11px}#mermaid-1749023341419 .taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}#mermaid-1749023341419 .taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}#mermaid-1749023341419 .taskText0,#mermaid-1749023341419 .taskText1,#mermaid-1749023341419 .taskText2,#mermaid-1749023341419 .taskText3{fill:#fff}#mermaid-1749023341419 .task0,#mermaid-1749023341419 .task1,#mermaid-1749023341419 .task2,#mermaid-1749023341419 .task3{fill:#8a90dd;stroke:#534fbc}#mermaid-1749023341419 .taskTextOutside0,#mermaid-1749023341419 .taskTextOutside1,#mermaid-1749023341419 .taskTextOutside2,#mermaid-1749023341419 .taskTextOutside3{fill:#000}#mermaid-1749023341419 .active0,#mermaid-1749023341419 .active1,#mermaid-1749023341419 .active2,#mermaid-1749023341419 .active3{fill:#bfc7ff;stroke:#534fbc}#mermaid-1749023341419 .activeText0,#mermaid-1749023341419 .activeText1,#mermaid-1749023341419 .activeText2,#mermaid-1749023341419 .activeText3{fill:#000!important}#mermaid-1749023341419 .done0,#mermaid-1749023341419 .done1,#mermaid-1749023341419 .done2,#mermaid-1749023341419 .done3{stroke:grey;fill:#d3d3d3;stroke-width:2}#mermaid-1749023341419 .doneText0,#mermaid-1749023341419 .doneText1,#mermaid-1749023341419 .doneText2,#mermaid-1749023341419 .doneText3{fill:#000!important}#mermaid-1749023341419 .crit0,#mermaid-1749023341419 .crit1,#mermaid-1749023341419 .crit2,#mermaid-1749023341419 .crit3{stroke:#f88;fill:red;stroke-width:2}#mermaid-1749023341419 .activeCrit0,#mermaid-1749023341419 .activeCrit1,#mermaid-1749023341419 .activeCrit2,#mermaid-1749023341419 .activeCrit3{stroke:#f88;fill:#bfc7ff;stroke-width:2}#mermaid-1749023341419 .doneCrit0,#mermaid-1749023341419 .doneCrit1,#mermaid-1749023341419 .doneCrit2,#mermaid-1749023341419 .doneCrit3{stroke:#f88;fill:#d3d3d3;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}#mermaid-1749023341419 .activeCritText0,#mermaid-1749023341419 .activeCritText1,#mermaid-1749023341419 .activeCritText2,#mermaid-1749023341419 .activeCritText3,#mermaid-1749023341419 .doneCritText0,#mermaid-1749023341419 .doneCritText1,#mermaid-1749023341419 .doneCritText2,#mermaid-1749023341419 .doneCritText3{fill:#000!important}#mermaid-1749023341419 .titleText{text-anchor:middle;font-size:18px;fill:#000}
#mermaid-1749023341419 g.classGroup text{fill:#9370db;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:10px}#mermaid-1749023341419 g.classGroup rect{fill:#ececff;stroke:#9370db}#mermaid-1749023341419 g.classGroup line{stroke:#9370db;stroke-width:1}#mermaid-1749023341419 .classLabel .box{stroke:none;stroke-width:0;fill:#ececff;opacity:.5}#mermaid-1749023341419 .classLabel .label{fill:#9370db;font-size:10px}#mermaid-1749023341419 .relation{stroke:#9370db;stroke-width:1;fill:none}#mermaid-1749023341419 #compositionEnd,#mermaid-1749023341419 #compositionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1749023341419 #aggregationEnd,#mermaid-1749023341419 #aggregationStart{fill:#ececff;stroke:#9370db;stroke-width:1}#mermaid-1749023341419 #dependencyEnd,#mermaid-1749023341419 #dependencyStart,#mermaid-1749023341419 #extensionEnd,#mermaid-1749023341419 #extensionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1749023341419 .branch-label,#mermaid-1749023341419 .commit-id,#mermaid-1749023341419 .commit-msg{fill:#d3d3d3;color:#d3d3d3}</style><style>#mermaid-1749023341419{color:#000;font:normal normal 400 normal 16px / normal "Times New Roman"}</style><g></g><g><line id="actor0" x1="75" y1="5" x2="75" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="0" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><line id="actor1" x1="275" y1="5" x2="275" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="200" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g><defs><marker id="arrowhead" refX="5" refY="2" markerWidth="6" markerHeight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><defs><marker id="crosshead" markerWidth="15" markerHeight="8" orient="auto" refX="16" refY="4"><path fill="black" stroke="#000000" stroke-width="1px" d="M 9,2 V 6 L16,4 Z" style="stroke-dasharray: 0, 0;"></path><path fill="none" stroke="#000000" stroke-width="1px" d="M 0,1 L 6,7 M 6,1 L 0,7" style="stroke-dasharray: 0, 0;"></path></marker></defs><g><text x="175" y="93" class="messageText" style="text-anchor: middle;">Hello John, how are you?</text><line x1="275" y1="100" x2="75" y2="100" class="messageLine0" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="fill: none;"></line></g><g><text x="175" y="128" class="messageText" style="text-anchor: middle;">Great!</text><line x1="75" y1="135" x2="275" y2="135" class="messageLine1" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="stroke-dasharray: 3, 3; fill: none;"></line></g><g><rect x="0" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><rect x="200" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g></svg> </div> <hr/> <h2 id="tweets">Tweets</h2> <p>An example of displaying a tweet:</p> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="sv" dir="ltr">jekyll-twitter-plugin (1.0.0): A Liquid tag plugin for Jekyll that renders Tweets from Twitter API <a href="http://t.co/m4EIQPM9h4">http://t.co/m4EIQPM9h4</a></p>&mdash; RubyGems (@rubygems) <a href="https://twitter.com/rubygems/status/518821243320287232?ref_src=twsrc%5Etfw">October 5, 2014</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>An example of pulling from a timeline:</p> <div class="jekyll-twitter-plugin"><a class="twitter-timeline" data-width="500" data-tweet-limit="3" href="https://twitter.com/jekyllrb?ref_src=twsrc%5Etfw">Tweets by jekyllrb</a> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>For more details on using the plugin visit: <a href="https://github.com/rob-murray/jekyll-twitter-plugin">jekyll-twitter-plugin</a></p> <hr/> <h2 id="blockquotes">Blockquotes</h2> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. ‚ÄîAnais Nin </blockquote> <hr/> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you‚Äôll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code>-sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr/> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item <ul> <li>Unordered sub-list.</li> </ul> </li> <li>Actual numbers don‚Äôt matter, just that it‚Äôs a number <ol> <li>Ordered sub-list</li> </ol> </li> <li> <p>And another item.</p> <p>You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we‚Äôll use three here to also align the raw Markdown).</p> <p>To have a line break without a paragraph, you will need to use two trailing spaces. Note that this line is separate, but within the same paragraph. (This is contrary to the typical GFM line break behavior, where trailing spaces are not required.)</p> </li> </ol> <ul> <li>Unordered lists can use asterisks</li> <li>Or minuses</li> <li>Or pluses</li> </ul> <p><a href="https://www.google.com">I‚Äôm an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage">I‚Äôm an inline-style link with title</a></p> <p><a href="https://www.mozilla.org">I‚Äôm a reference-style link</a></p> <p><a href="../blob/master/LICENSE">I‚Äôm a relative reference to a repository file</a></p> <p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here‚Äôs our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"/></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"/></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Python syntax highlighting</span><span class="sh">"</span>
<span class="nf">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting. 
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don‚Äôt need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let‚Äôs keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here‚Äôs a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but‚Ä¶ This line is only separated by a single newline, so it‚Äôs a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[Your blog post's abstract. Please add your abstract or summary here and not in the main body of your text. Do not include math/latex or hyperlinks.]]></summary></entry></feed>